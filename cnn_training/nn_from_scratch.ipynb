{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import\n",
    "To handle paths pathlib included in python 3.x comes in handy.\n",
    "[http://deeplearning.net/data/mnist/] mnist data set from deeplearing, format is a python binary (pkl)\n",
    "\n",
    "We will use the request library to download zipped binary files and gzip to unzig the file.\n",
    "The dataset is a serialized numpy array and stored as a binary using pickle. We can use gzip and pickle libries to load the data as a tuple numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000,)\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle, gzip\n",
    "\n",
    "data_dir = Path('data')\n",
    "mnist_location = data_dir/'mnist'\n",
    "\n",
    "mnist_location.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "url='http://deeplearning.net/data/mnist/'\n",
    "filename='mnist.pkl.gz'\n",
    "\n",
    "if not (mnist_location/filename).exists():\n",
    "    content = requests.get(url+filename).content(mnist_location/filename).open('wb').write(content)\n",
    "    \n",
    "with gzip.open(mnist_location/filename) as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(y_train[49948])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127edc7f0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "# each row of x_train conataines a flattend images, we need to reshape it to 28x28 \n",
    "pyplot.imshow(x_train[49948].reshape((28,28)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model from scratch\n",
    "After converting numpy array to a pytorch tensor, we build a neural net from scratch.\n",
    "The model is built only with tensor operations and the use of gradients.\n",
    "For the weights, we set requires_grad after the initialization, since we don't want that step included in the gradient. (Note that a trailling _ in PyTorch signifies that the operation is performed in-place.)\n",
    "Initial weigths with Xavier initialisation by by multiplying with 1/sqrt(n)) \n",
    "\n",
    "proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-222b8f0633b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_train,y_train,x_valid,y_valid = map(torch.tensor, (x_train,y_train,x_valid,y_valid))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "weights = torch.randn(784,10)/math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to PyTorch's ability to calculate gradients automatically, we can use any standard Python function (or callable object) as a model! \n",
    "\n",
    "So let's just write a plain matrix multiplication and broadcasted addition to create a simple linear model. We also need an activation function, so we'll write `log_softmax` and use it. \n",
    "\n",
    "We use the '@' operator for the dot product operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(batch):\n",
    "    return log_softmax(batch @ weights + bias)\n",
    "\n",
    "def log_softmax(x):\n",
    "    #unsqueeze x along cols adds extra col x.exp... -> dim(x) X 1, such that result can be broadcasted.\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will call our function on one batch of data (in this case, 64 images). This is one forward pass. Note that our predictions won't be any better than random at this stage, since we start with random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-2.7073, -2.5841, -2.2565, -2.4422, -2.9635, -1.9985, -1.6499, -2.3197,\n",
       "         -2.3692, -2.3536], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "mini_batch = x_train[0:batch_size]\n",
    "preds = model(mini_batch)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preds tensor contains not only the tensor values, but also a gradient function. \n",
    "\n",
    "Let's implement negative log-likelihood to use as the loss function (again, we can just use standard Python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(preds, targets): \n",
    "    #pick the prob for correct class from predicted\n",
    "    probs = preds[range(targets.shape[0]), targets]\n",
    "    return -probs.mean()\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3637, grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch = y_train[0:batch_size]\n",
    "loss_func(preds, target_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also implement a function to calculate the accuracy of our model. \n",
    "\n",
    "For each prediction, if the index with the largest value matches the target value, then the prediction was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(probs, targets):\n",
    "    preds = torch.argmax(probs, dim=1) #argmax along rows\n",
    "    return (preds==targets).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy tensor(0.0312)\n"
     ]
    }
   ],
   "source": [
    "print('accuracy', accuracy(preds, target_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run a training loop. For each iteration, we will:\n",
    "\n",
    "- select a mini-batch of data (of size batch_size)\n",
    "- use the model to make predictions\n",
    "- calculate the loss\n",
    "- `loss.backward()` updates the gradients of the model, in this case, weights and bias.\n",
    "- We now use these gradients to update the weights and bias. We do this within the torch.no_grad() context manager, because we do not want these actions to be recorded for our next calculation of the gradient. You can read more about how PyTorch's Autograd records operations here.\n",
    "- We then set the gradients to zero, so that we are ready for the next loop. Otherwise, our gradients would record a running tally of all the operations that had happened (i.e. loss.backward() adds the gradients to whatever is already stored, rather than replacing them).\n",
    "\n",
    "Handy tip: you can use the standard python debugger to step through PyTorch code, allowing you to check the various variable values at each step. Uncomment set_trace() below to try it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "lr = 0.5   # learning rate\n",
    "epochs = 100 # how many epochs to train for\n",
    "batch_size = 64\n",
    "n,c = x_train.shape\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//batch_size + 1):\n",
    "#         set_trace()\n",
    "        start_i = i*batch_size\n",
    "        end_i = start_i+batch_size\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2444, grad_fn=<NegBackward>), tensor(0.9302))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(x_train), y_train), accuracy(model(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
